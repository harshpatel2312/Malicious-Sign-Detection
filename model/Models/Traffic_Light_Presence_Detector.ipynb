{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe065ced-8514-4c5e-b9a2-b2ccf89f5521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from screeninfo import get_monitors\n",
    "import pickle\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgba2rgb, gray2rgb\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import threading\n",
    "import logging\n",
    "from flask import Flask, jsonify\n",
    "import time\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1527d943-5216-4846-982d-e35affa7f29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image_with_unknown(img, model, threshold=0.1):\n",
    "   \n",
    "    #img = imread(image_path)\n",
    "    ##RGB conversion\n",
    "    if len(img.shape) == 2:\n",
    "        img = gray2rgb(img)\n",
    "    elif img.shape[-1] == 4:\n",
    "        img = rgba2rgb(img)\n",
    "\n",
    "    #Prediction\n",
    "    img = resize(img, img_size, anti_aliasing=True).flatten()\n",
    "    probabilities = model.predict_proba(img.reshape(1, -1))\n",
    "    max_confidence = np.max(probabilities)\n",
    "    \n",
    "    return model.predict(img.reshape(1, -1))[0] if max_confidence >= threshold else \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0269060-20da-4c85-babf-0e67e908a2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(image, test_results, best_estimator):\n",
    "    if image is not None and image.size  > 0:\n",
    "        # Classify the image\n",
    "        result = classify_image_with_unknown(image, best_estimator, threshold=0.1)\n",
    "        test_results[f\"frame_{frame_count}\"] = result\n",
    "        print(f\"Frame: {frame_count}, Classification Result: {result}\")\n",
    "    else:\n",
    "        print(f\"Skipping frame_{frame_count}: Not a useful frame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2372ae28-97c7-430f-b8f0-44e614d7fd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad18658e-acc6-4ae1-9974-66542f403914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_flask():\n",
    "    app.run(debug=False, port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df3e4adc-4f73-4271-951e-b29f2551fba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/data', methods=['GET'])\n",
    "def get_data():\n",
    "    return jsonify(metrics), 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7247158a-862b-418e-b831-281c27ed86ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "threading.Thread(target=run_flask, daemon=True).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46db1906-68f7-4e2b-94e3-bbcafb5347be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "[2025-04-03 02:39:07,898] ERROR in app: Exception on /data [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 1473, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 882, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 880, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 865, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_21952\\1791911797.py\", line 3, in get_data\n",
      "    return jsonify(metrics), 200\n",
      "                   ^^^^^^^\n",
      "NameError: name 'metrics' is not defined\n",
      "127.0.0.1 - - [03/Apr/2025 02:39:07] \"GET /data HTTP/1.1\" 500 -\n"
     ]
    }
   ],
   "source": [
    "# Loading the trained model\n",
    "model_file_name = r\"E:\\Education\\Projects\\Machine Learning\\Computer Vision\\Malicious-Sign-Detection\\model\\Models\\classifier\"\n",
    "with open(model_file_name, 'rb') as file:\n",
    "    best_estimator = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e488ca44-19e7-4e63-94af-17b258a86e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading calssification_report\n",
    "with open('Scripts/Resources/classification_report', 'rb') as f:\n",
    "    report = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cef036e0-ca22-474e-802d-b4ce7490455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_macro = report['macro avg']['precision']\n",
    "recall_macro = report['macro avg']['recall']\n",
    "f1_score_macro = report['macro avg']['f1-score']\n",
    "support_macro = report['macro avg']['support']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa4b8011-ec6d-445e-9354-9b7258561e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    #\"Classification_Result\": result,\n",
    "    #\"Validation_Accuracy\": accuracy,\n",
    "    \"Execution_Time_of_Prediction\": None,\n",
    "    \"Macro_Precision_of_Training\": precision_macro,\n",
    "    \"Macro_Recall_of_Training\": recall_macro,\n",
    "    \"Macro_F1_score_of_Training\": f1_score_macro,\n",
    "    \"Macro_Support_of_Training\": support_macro,\n",
    "    \"Test_Results\" : []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6485936f-7c0c-4721-a1c4-a4d3f331ff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (15, 15) # Resizing for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1148d0a3-d01d-49b0-8872-ff0279d9d64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get screen resolution\n",
    "screen = get_monitors()[0]  # Get the primary monitor\n",
    "screen_width, screen_height = screen.width, screen.height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bdd5b68-bbeb-467c-a422-d3dc44621097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLO model for traffic light detection\n",
    "model = YOLO('yolov8n.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "214ced11-dceb-47e2-872b-a938c6a94a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the video\n",
    "video_path = r\"..\\Resources\\Videos\\20250402_181308.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e2037f1-dd27-44f1-84ca-42c34dc3d3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Cannot open video file!\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5040e4e7-f2f9-4fef-8e33-e354ab6e161c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Apr/2025 02:39:11] \"GET /data HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 128.7ms\n",
      "Speed: 5.6ms preprocess, 128.7ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 53.3ms\n",
      "Speed: 2.6ms preprocess, 53.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 56.8ms\n",
      "Speed: 2.3ms preprocess, 56.8ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Apr/2025 02:39:18] \"GET /data HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 kite, 56.6ms\n",
      "Speed: 2.0ms preprocess, 56.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Apr/2025 02:39:21] \"GET /data HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 52.7ms\n",
      "Speed: 2.2ms preprocess, 52.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 59.1ms\n",
      "Speed: 2.1ms preprocess, 59.1ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Frame: 354, Classification Result: yellow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Apr/2025 02:39:25] \"GET /data HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 52.9ms\n",
      "Speed: 2.0ms preprocess, 52.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Apr/2025 02:39:29] \"GET /data HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 50.4ms\n",
      "Speed: 2.1ms preprocess, 50.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 60.8ms\n",
      "Speed: 2.0ms preprocess, 60.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Apr/2025 02:39:33] \"GET /data HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 55.3ms\n",
      "Speed: 2.2ms preprocess, 55.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Apr/2025 02:39:37] \"GET /data HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 truck, 52.9ms\n",
      "Speed: 2.3ms preprocess, 52.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Apr/2025 02:39:40] \"GET /data HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 car, 71.9ms\n",
      "Speed: 2.0ms preprocess, 71.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 59.2ms\n",
      "Speed: 2.8ms preprocess, 59.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Apr/2025 02:39:44] \"GET /data HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 car, 1 boat, 55.5ms\n",
      "Speed: 2.5ms preprocess, 55.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 56.7ms\n",
      "Speed: 2.0ms preprocess, 56.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Apr/2025 02:39:48] \"GET /data HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 car, 63.0ms\n",
      "Speed: 2.2ms preprocess, 63.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Apr/2025 02:39:52] \"GET /data HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 car, 70.6ms\n",
      "Speed: 2.2ms preprocess, 70.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 56.3ms\n",
      "Speed: 2.3ms preprocess, 56.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Apr/2025 02:39:56] \"GET /data HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 car, 1 truck, 57.2ms\n",
      "Speed: 2.1ms preprocess, 57.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Apr/2025 02:40:00] \"GET /data HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 car, 2 trucks, 72.0ms\n",
      "Speed: 3.1ms preprocess, 72.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 82.1ms\n",
      "Speed: 3.0ms preprocess, 82.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Apr/2025 02:40:04] \"GET /data HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 car, 57.5ms\n",
      "Speed: 2.3ms preprocess, 57.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Apr/2025 02:40:08] \"GET /data HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 car, 64.9ms\n",
      "Speed: 2.8ms preprocess, 64.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 62.9ms\n",
      "Speed: 2.9ms preprocess, 62.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Apr/2025 02:40:12] \"GET /data HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 boat, 55.2ms\n",
      "Speed: 2.1ms preprocess, 55.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 boat, 57.7ms\n",
      "Speed: 2.3ms preprocess, 57.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Apr/2025 02:40:15] \"GET /data HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 1 truck, 1 traffic light, 55.9ms\n",
      "Speed: 2.0ms preprocess, 55.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Frame: 1593, Classification Result: green\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Apr/2025 02:40:19] \"GET /data HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 56.5ms\n",
      "Speed: 2.0ms preprocess, 56.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Apr/2025 02:40:23] \"GET /data HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 cars, 1 truck, 2 traffic lights, 65.2ms\n",
      "Speed: 2.6ms preprocess, 65.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Frame: 1711, Classification Result: green\n",
      "\n",
      "0: 384x640 1 bus, 2 traffic lights, 56.2ms\n",
      "Speed: 2.1ms preprocess, 56.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Frame: 1770, Classification Result: red\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Apr/2025 02:40:27] \"GET /data HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 car, 1 truck, 2 traffic lights, 63.1ms\n",
      "Speed: 2.1ms preprocess, 63.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Frame: 1829, Classification Result: red\n",
      "\n",
      "0: 384x640 1 traffic light, 58.4ms\n",
      "Speed: 2.2ms preprocess, 58.4ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Apr/2025 02:40:31] \"GET /data HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame: 1888, Classification Result: green\n",
      "\n",
      "0: 384x640 1 car, 1 boat, 54.1ms\n",
      "Speed: 2.0ms preprocess, 54.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Apr/2025 02:40:35] \"GET /data HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 56.6ms\n",
      "Speed: 2.3ms preprocess, 56.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 truck, 62.6ms\n",
      "Speed: 2.2ms preprocess, 62.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Apr/2025 02:40:39] \"GET /data HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 54.8ms\n",
      "Speed: 2.4ms preprocess, 54.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Apr/2025 02:40:42] \"GET /data HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 car, 60.6ms\n",
      "Speed: 2.3ms preprocess, 60.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 54.8ms\n",
      "Speed: 2.5ms preprocess, 54.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Apr/2025 02:40:46] \"GET /data HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 cars, 2 trucks, 67.4ms\n",
      "Speed: 3.0ms preprocess, 67.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Apr/2025 02:40:50] \"GET /data HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 car, 1 truck, 67.2ms\n",
      "Speed: 2.9ms preprocess, 67.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 55.0ms\n",
      "Speed: 2.2ms preprocess, 55.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Apr/2025 02:40:54] \"GET /data HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame: 2419, Classification Result: green\n",
      "\n",
      "0: 384x640 (no detections), 54.5ms\n",
      "Speed: 2.0ms preprocess, 54.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Apr/2025 02:40:58] \"GET /data HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 55.7ms\n",
      "Speed: 2.1ms preprocess, 55.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "End of video or cannot access the video.\n",
      "Total frames processed: 2551\n"
     ]
    }
   ],
   "source": [
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_count = 0\n",
    "\n",
    "cv2.namedWindow(\"Video\", cv2.WINDOW_NORMAL)  # Create a resizable window\n",
    "start_time = time.time()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"End of video or cannot access the video.\")\n",
    "        break\n",
    "\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    frame_count += 1\n",
    "    # Process every frame or skip to reduce processing\n",
    "    if frame_count % int(fps) != 0:  # Process one frame per second\n",
    "        continue\n",
    "\n",
    "    # YOLO detection\n",
    "    results = model(frame)  # Run the YOLO model on the current frame\n",
    "    \n",
    "    # Access the first result in the list\n",
    "    result = results[0]\n",
    "    \n",
    "    test_results = {}\n",
    "    \n",
    "    # Iterate through detected boxes\n",
    "    for box in result.boxes:\n",
    "        class_id = int(box.cls)  # Object class ID\n",
    "        if class_id == 9:  # class 9 corresponds to traffic lights in YOLO\n",
    "            # Extract bounding box coordinates\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])  # Bounding box coordinates\n",
    "            traffic_light_roi = frame[y1:y2, x1:x2]  # Crop the traffic light region\n",
    "\n",
    "            test(traffic_light_roi, test_results, best_estimator)\n",
    "            metrics[\"Test_Results\"].append(test_results)\n",
    "\n",
    "            break  # Avoid multiple saves for the same frame\n",
    "            \n",
    "    # Resize frame to fit screen size\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "    aspect_ratio = frame_width / frame_height\n",
    "\n",
    "    # Calculate new dimensions while maintaining aspect ratio\n",
    "    if frame_width > screen_width or frame_height > screen_height:\n",
    "        if frame_width / screen_width > frame_height / screen_height:\n",
    "            new_width = screen_width\n",
    "            new_height = int(screen_width / aspect_ratio)\n",
    "        else:\n",
    "            new_height = screen_height\n",
    "            new_width = int(screen_height * aspect_ratio)\n",
    "    else:\n",
    "        new_width, new_height = frame_width, frame_height\n",
    "\n",
    "    resized_frame = cv2.resize(frame, (new_width, new_height))\n",
    "    cv2.imshow(\"Video\", resized_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to quit\n",
    "        break\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "metrics[\"Execution_Time_of_Prediction\"] = execution_time\n",
    "\n",
    "print(f\"Total frames processed: {frame_count}\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
