{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[9]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from skimage.color import rgba2rgb\n",
    "import pickle\n",
    "import time\n",
    "from flask import Flask, jsonify\n",
    "import threading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[10]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "start_time=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = r\"E:\\Education\\Projects\\Machine Learning\\Computer Vision\\Malicious-Sign-Detection\\carla_lights\\traffic_light_data\"\n",
    "categories = ['green', 'red', 'yellow', \"unknown\"]\n",
    "blurred_suffix = ' blurred'  \n",
    "img_size = (15, 15)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = []\n",
    "labels_train = []\n",
    "data_val = []\n",
    "labels_val = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[11]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(category, folder_type, data, labels):\n",
    "    \n",
    "    category_path = os.path.join(input_dir, folder_type, category)\n",
    "    blurred_path = os.path.join(input_dir, folder_type, f\"{category}{blurred_suffix}\")\n",
    "    for folder in [category_path, blurred_path]:\n",
    "        if not os.path.exists(folder):\n",
    "            continue\n",
    "        for file in os.listdir(folder):\n",
    "            img_path = os.path.join(folder, file)\n",
    "            try:\n",
    "                img = imread(img_path)\n",
    "                #Converting RGBA to RGB if necessary\n",
    "                if img.shape[-1] == 4:  # If image has 4 channels (RGBA)\n",
    "                    img = rgba2rgb(img)\n",
    "                img = resize(img, img_size)\n",
    "                if img.shape == (15, 15, 3):  \n",
    "                    data.append(img.flatten())\n",
    "                    labels.append(category)\n",
    "                else:\n",
    "                    print(f\"Skipping {file}: Invalid shape after resize {img.shape}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in categories:\n",
    "    load_images(category, 'train', data_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in categories:\n",
    "    load_images(category, 'val', data_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(data_train)\n",
    "y_train = np.array(labels_train)\n",
    "x_val = np.array(data_val)\n",
    "y_val = np.array(labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (4100, 675), y_train shape: (4100,)\n",
      "x_val shape: (1396, 675), y_val shape: (1396,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"x_val shape: {x_val.shape}, y_val shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[12]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " training SVC model with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC(probability=True)\n",
    "parameters = [{'gamma': [0.01, 0.001, 0.0001], 'C': [1, 10, 100, 1000]}]\n",
    "#parameters = [{'gamma': [0.01, 0.001, 0.0001], 'C': [1, 10, 100, 1000]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-12 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-12 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-12 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-12 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-12 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-12 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-12 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-12 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-12 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-12 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=SVC(probability=True),\n",
       "             param_grid=[{&#x27;C&#x27;: [1, 10, 100, 1000],\n",
       "                          &#x27;gamma&#x27;: [0.01, 0.001, 0.0001]}])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=3, estimator=SVC(probability=True),\n",
       "             param_grid=[{&#x27;C&#x27;: [1, 10, 100, 1000],\n",
       "                          &#x27;gamma&#x27;: [0.01, 0.001, 0.0001]}])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: SVC</label><div class=\"sk-toggleable__content fitted\"><pre>SVC(C=100, gamma=0.001, probability=True)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(C=100, gamma=0.001, probability=True)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=SVC(probability=True),\n",
       "             param_grid=[{'C': [1, 10, 100, 1000],\n",
       "                          'gamma': [0.01, 0.001, 0.0001]}])"
      ]
     },
     "execution_count": 793,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(classifier, parameters, cv=3)\n",
    "grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 92.62%\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_estimator.predict(x_val)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       green       0.94      0.76      0.84       200\n",
      "         red       0.97      0.86      0.92       206\n",
      "     unknown       0.92      0.97      0.94       823\n",
      "      yellow       0.91      0.98      0.94       167\n",
      "\n",
      "    accuracy                           0.93      1396\n",
      "   macro avg       0.93      0.89      0.91      1396\n",
      "weighted avg       0.93      0.93      0.92      1396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[13]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def classify_image(image_path, model, threshold=0.7, spread_threshold=0.2):\\n    img = imread(image_path)\\n    if img.shape[-1] == 4:  # Convert RGBA to RGB if necessary\\n        img = rgba2rgb(img)\\n    img = resize(img, img_size).flatten()\\n    img = img.reshape(1, -1)\\n\\n    # Predict\\n    probabilities = model.predict_proba(img)[0]\\n    max_confidence = np.max(probabilities)\\n    sorted_probs = np.sort(probabilities)\\n    spread = sorted_probs[-1] - sorted_probs[-2]\\n\\n    if max_confidence < threshold or spread < spread_threshold:\\n        return \"unknown\"\\n    return model.predict(img)[0]'"
      ]
     },
     "execution_count": 800,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def classify_image_with_unknown(image_path, model, threshold=0.7):\n",
    "   \n",
    "    img = imread(image_path)\n",
    "    ##RGB conversion\n",
    "    if img.shape[-1] == 4:  \n",
    "        img = rgba2rgb(img)\n",
    "    img = resize(img, img_size).flatten()\n",
    "    img = img.reshape(1, -1)  \n",
    "\n",
    "    ## Prediction\n",
    "    probabilities = model.predict_proba(img)\n",
    "    max_confidence = np.max(probabilities)\n",
    "    predicted_class = model.predict(img)[0]\n",
    "    if max_confidence < threshold:\n",
    "        return \"unknown\"\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[14]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_name = r\"E:\\Education\\Projects\\Machine Learning\\Computer Vision\\Malicious-Sign-Detection\\classifier\"  # Specify the filename\n",
    "with open(model_file_name, 'wb') as file:\n",
    "    pickle.dump(best_estimator, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as E:\\Education\\Projects\\Machine Learning\\Computer Vision\\Malicious-Sign-Detection\\classifier\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model saved as {model_file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[16]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path to the test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = r\"E:\\Education\\Projects\\Machine Learning\\Computer Vision\\Malicious-Sign-Detection\\carla_lights\\traffic_light_data\\test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if directory exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(test_image_path):\n",
    "    print(f\"Error: The directory '{test_images_dir}' does not exist.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through test images and classify them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: traffic_light_frame10500.png, Classification Result: unknown\n",
      "Image: traffic_light_frame11340.png, Classification Result: unknown\n",
      "Image: traffic_light_frame11400.png, Classification Result: unknown\n",
      "Image: traffic_light_frame11430.png, Classification Result: unknown\n",
      "Image: traffic_light_frame11460.png, Classification Result: unknown\n",
      "Image: traffic_light_frame11490.png, Classification Result: red\n",
      "Image: traffic_light_frame11520.png, Classification Result: unknown\n",
      "Image: traffic_light_frame11550.png, Classification Result: unknown\n",
      "Image: traffic_light_frame11580.png, Classification Result: red\n",
      "Image: traffic_light_frame11610.png, Classification Result: unknown\n",
      "Image: traffic_light_frame11640.png, Classification Result: red\n",
      "Image: traffic_light_frame11670.png, Classification Result: red\n",
      "Image: traffic_light_frame11700.png, Classification Result: red\n",
      "Image: traffic_light_frame11730.png, Classification Result: unknown\n",
      "Image: traffic_light_frame11760.png, Classification Result: unknown\n",
      "Image: traffic_light_frame11790.png, Classification Result: green\n",
      "Image: traffic_light_frame11820.png, Classification Result: unknown\n",
      "Image: traffic_light_frame11850.png, Classification Result: unknown\n",
      "Image: traffic_light_frame11880.png, Classification Result: red\n",
      "Image: traffic_light_frame11910.png, Classification Result: unknown\n",
      "Image: traffic_light_frame11940.png, Classification Result: unknown\n",
      "Image: traffic_light_frame11970.png, Classification Result: unknown\n",
      "Image: traffic_light_frame12000.png, Classification Result: unknown\n",
      "Image: traffic_light_frame12030.png, Classification Result: unknown\n",
      "Image: traffic_light_frame12060.png, Classification Result: green\n",
      "Image: traffic_light_frame12090.png, Classification Result: green\n",
      "Image: traffic_light_frame12120.png, Classification Result: green\n",
      "Image: traffic_light_frame12150.png, Classification Result: unknown\n",
      "Image: traffic_light_frame12180.png, Classification Result: green\n",
      "Image: traffic_light_frame12210.png, Classification Result: green\n",
      "Image: traffic_light_frame12240.png, Classification Result: unknown\n",
      "Image: traffic_light_frame12270.png, Classification Result: unknown\n",
      "Image: traffic_light_frame12690.png, Classification Result: unknown\n",
      "Image: traffic_light_frame1590.png, Classification Result: unknown\n",
      "Image: traffic_light_frame1650.png, Classification Result: unknown\n",
      "Image: traffic_light_frame1710.png, Classification Result: unknown\n",
      "Image: traffic_light_frame1740.png, Classification Result: red\n",
      "Image: traffic_light_frame1770.png, Classification Result: red\n",
      "Image: traffic_light_frame1800.png, Classification Result: red\n",
      "Image: traffic_light_frame1830.png, Classification Result: red\n",
      "Image: traffic_light_frame1860.png, Classification Result: red\n",
      "Image: traffic_light_frame1890.png, Classification Result: red\n",
      "Image: traffic_light_frame1920.png, Classification Result: unknown\n",
      "Image: traffic_light_frame1950.png, Classification Result: unknown\n",
      "Image: traffic_light_frame1980.png, Classification Result: red\n",
      "Image: traffic_light_frame2010.png, Classification Result: unknown\n",
      "Image: traffic_light_frame2040.png, Classification Result: red\n",
      "Image: traffic_light_frame2070.png, Classification Result: red\n",
      "Image: traffic_light_frame2100.png, Classification Result: red\n",
      "Image: traffic_light_frame2130.png, Classification Result: red\n",
      "Image: traffic_light_frame2160.png, Classification Result: red\n",
      "Image: traffic_light_frame2190.png, Classification Result: red\n",
      "Image: traffic_light_frame2220.png, Classification Result: red\n",
      "Image: traffic_light_frame2250.png, Classification Result: red\n",
      "Image: traffic_light_frame2280.png, Classification Result: unknown\n",
      "Image: traffic_light_frame2310.png, Classification Result: red\n",
      "Image: traffic_light_frame2340.png, Classification Result: red\n",
      "Image: traffic_light_frame2370.png, Classification Result: red\n",
      "Image: traffic_light_frame2400.png, Classification Result: red\n",
      "Image: traffic_light_frame2430.png, Classification Result: red\n",
      "Image: traffic_light_frame2460.png, Classification Result: red\n",
      "Image: traffic_light_frame2490.png, Classification Result: unknown\n",
      "Image: traffic_light_frame2520.png, Classification Result: red\n",
      "Image: traffic_light_frame2550.png, Classification Result: red\n",
      "Image: traffic_light_frame2580.png, Classification Result: red\n",
      "Image: traffic_light_frame2610.png, Classification Result: red\n",
      "Image: traffic_light_frame2640.png, Classification Result: red\n",
      "Image: traffic_light_frame2670.png, Classification Result: red\n",
      "Image: traffic_light_frame2700.png, Classification Result: red\n",
      "Image: traffic_light_frame2730.png, Classification Result: red\n",
      "Image: traffic_light_frame2760.png, Classification Result: red\n",
      "Image: traffic_light_frame2790.png, Classification Result: red\n",
      "Image: traffic_light_frame2820.png, Classification Result: red\n",
      "Image: traffic_light_frame2850.png, Classification Result: red\n",
      "Image: traffic_light_frame2880.png, Classification Result: red\n",
      "Image: traffic_light_frame2910.png, Classification Result: red\n",
      "Image: traffic_light_frame2940.png, Classification Result: red\n",
      "Image: traffic_light_frame2970.png, Classification Result: unknown\n",
      "Image: traffic_light_frame3000.png, Classification Result: red\n",
      "Image: traffic_light_frame3030.png, Classification Result: unknown\n",
      "Image: traffic_light_frame3060.png, Classification Result: unknown\n",
      "Image: traffic_light_frame3090.png, Classification Result: unknown\n",
      "Image: traffic_light_frame3120.png, Classification Result: red\n",
      "Image: traffic_light_frame3150.png, Classification Result: red\n",
      "Image: traffic_light_frame3180.png, Classification Result: unknown\n",
      "Image: traffic_light_frame3210.png, Classification Result: red\n",
      "Image: traffic_light_frame3240.png, Classification Result: red\n",
      "Image: traffic_light_frame3270.png, Classification Result: red\n",
      "Image: traffic_light_frame3300.png, Classification Result: red\n",
      "Image: traffic_light_frame3330.png, Classification Result: red\n",
      "Image: traffic_light_frame3360.png, Classification Result: red\n",
      "Image: traffic_light_frame3390.png, Classification Result: red\n",
      "Image: traffic_light_frame3420.png, Classification Result: red\n",
      "Image: traffic_light_frame3450.png, Classification Result: red\n",
      "Image: traffic_light_frame3480.png, Classification Result: red\n",
      "Image: traffic_light_frame3510.png, Classification Result: red\n",
      "Image: traffic_light_frame3540.png, Classification Result: red\n",
      "Image: traffic_light_frame3570.png, Classification Result: red\n",
      "Image: traffic_light_frame3600.png, Classification Result: red\n",
      "Image: traffic_light_frame3630.png, Classification Result: red\n",
      "Image: traffic_light_frame3660.png, Classification Result: red\n",
      "Image: traffic_light_frame3690.png, Classification Result: red\n",
      "Image: traffic_light_frame3720.png, Classification Result: red\n",
      "Image: traffic_light_frame3750.png, Classification Result: red\n",
      "Image: traffic_light_frame3780.png, Classification Result: unknown\n",
      "Image: traffic_light_frame3810.png, Classification Result: red\n",
      "Image: traffic_light_frame3840.png, Classification Result: red\n",
      "Image: traffic_light_frame3870.png, Classification Result: red\n",
      "Image: traffic_light_frame3900.png, Classification Result: red\n",
      "Image: traffic_light_frame3990.png, Classification Result: unknown\n",
      "Image: traffic_light_frame4560.png, Classification Result: red\n",
      "Image: traffic_light_frame4590.png, Classification Result: unknown\n",
      "Image: traffic_light_frame4620.png, Classification Result: red\n",
      "Image: traffic_light_frame4650.png, Classification Result: red\n",
      "Image: traffic_light_frame4680.png, Classification Result: red\n",
      "Image: traffic_light_frame4710.png, Classification Result: red\n",
      "Image: traffic_light_frame4740.png, Classification Result: red\n",
      "Image: traffic_light_frame4770.png, Classification Result: red\n",
      "Image: traffic_light_frame4800.png, Classification Result: red\n",
      "Image: traffic_light_frame4830.png, Classification Result: red\n",
      "Image: traffic_light_frame4860.png, Classification Result: red\n",
      "Image: traffic_light_frame4890.png, Classification Result: red\n",
      "Image: traffic_light_frame4920.png, Classification Result: red\n",
      "Image: traffic_light_frame4950.png, Classification Result: red\n",
      "Image: traffic_light_frame4980.png, Classification Result: red\n",
      "Image: traffic_light_frame5190.png, Classification Result: unknown\n",
      "Image: traffic_light_frame5220.png, Classification Result: unknown\n",
      "Image: traffic_light_frame5430.png, Classification Result: unknown\n",
      "Image: traffic_light_frame5580.png, Classification Result: unknown\n",
      "Image: traffic_light_frame5610.png, Classification Result: unknown\n",
      "Image: traffic_light_frame5670.png, Classification Result: unknown\n",
      "Image: traffic_light_frame5820.png, Classification Result: unknown\n",
      "Image: traffic_light_frame5880.png, Classification Result: unknown\n",
      "Image: traffic_light_frame5910.png, Classification Result: red\n",
      "Image: traffic_light_frame6000.png, Classification Result: unknown\n",
      "Image: traffic_light_frame6060.png, Classification Result: unknown\n",
      "Image: traffic_light_frame6240.png, Classification Result: unknown\n",
      "Image: traffic_light_frame9330.png, Classification Result: unknown\n",
      "Image: traffic_light_frame9360.png, Classification Result: unknown\n",
      "Image: traffic_light_frame9390.png, Classification Result: unknown\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(test_image_path):\n",
    "    image_path = os.path.join(test_image_path, file)\n",
    "    if os.path.isfile(image_path) and file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "        # Classify the image\n",
    "        result = classify_image_with_unknown(image_path, best_estimator, threshold=0.5)\n",
    "        test_results[file] = result\n",
    "        print(f\"Image: {file}, Classification Result: {result}\")\n",
    "    else:\n",
    "        print(f\"Skipping {file}: Not a valid image file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "etrics to be streamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_time = end_time - start_time\n",
    "report = classification_report(y_val, y_pred, output_dict=True)\n",
    "precision_macro = report['macro avg']['precision']\n",
    "recall_macro = report['macro avg']['recall']\n",
    "f1_score_macro = report['macro avg']['f1-score']\n",
    "support_macro = report['macro avg']['support']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"Classification_Result\": result,\n",
    "    \"Validation_Accuracy\": accuracy,\n",
    "    \"Execution_Time\": execution_time,\n",
    "    \"Macro_Precision\": precision_macro,\n",
    "    \"Macro_Recall\": recall_macro,\n",
    "    \"Macro_F1_score\": f1_score_macro,\n",
    "    \"Macro_Support\": support_macro,\n",
    "    \"Test_Results\" : test_results\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_flask():\n",
    "    app.run(debug=False, port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/data', methods=['GET'])\n",
    "def get_data():\n",
    "    return jsonify(metrics), 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    threading.Thread(target=run_flask, daemon=True).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
